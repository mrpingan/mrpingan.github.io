<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://mrpingan.github.io</id>
    <title>Ping&apos;s Home</title>
    <updated>2020-03-24T15:40:41.051Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://mrpingan.github.io"/>
    <link rel="self" href="https://mrpingan.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://mrpingan.github.io/images/avatar.png</logo>
    <icon>https://mrpingan.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Ping&apos;s Home</rights>
    <entry>
        <title type="html"><![CDATA[nginx防止爬虫爬页面]]></title>
        <id>https://mrpingan.github.io/post/nginx-fang-zhi-pa-chong-pa-ye-mian</id>
        <link href="https://mrpingan.github.io/post/nginx-fang-zhi-pa-chong-pa-ye-mian">
        </link>
        <updated>2020-03-24T15:33:27.000Z</updated>
        <content type="html"><![CDATA[<h1 id="方法一">方法一</h1>
<p>修改nginx，匹配到爬虫的ua，直接返回403</p>
<pre><code class="language-nginx">server { 
	listen 80; 
	server_name 127.0.0.1; 
	#添加如下内容即可防止爬虫
	if ($http_user_agent ~* “qihoobot|Baiduspider|Googlebot|Googlebot-Mobile|Googlebot-Image|Mediapartners-Google|Adsbot-Google|Feedfetcher-Google|Yahoo! Slurp|Yahoo! Slurp China|YoudaoBot|Sosospider|Sogou spider|Sogou web spider|MSNBot|ia_archiver|Tomato Bot”) 
	return 403; 
} 
</code></pre>
<h1 id="方法二">方法二</h1>
<p>网站下增加<strong>Robots.txt</strong>，放在站点根目录<br>
在http://tool.chinaz.com/robots/站点可以针对现在的搜索引擎按照想要的规则生成robots.txt文件。<br>
robots.txt是搜索引擎中访问网站的时候要查看的第一个文件。robots.txt文件告诉蜘蛛程序在服务器上什么文件是可以被查看的。<br>
当一个搜索蜘蛛访问一个站点时，它会首先检查该站点根目录下是否存在robots.txt，如果存在，搜索机器人就会按照该文件中的内容来确定访问的范围；如果该文件不存在，所有的搜索蜘蛛将能够访问网站上所有没有被口令保护的页面。百度官方建议，仅当您的网站包含不希望被搜索引擎收录的内容时，才需要使用robots.txt文件。如果您希望搜索引擎收录网站上所有内容，请勿建立robots.txt文件。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[iptables查看数据包传输过程]]></title>
        <id>https://mrpingan.github.io/post/iptables-cha-kan-shu-ju-bao-chuan-shu-guo-cheng</id>
        <link href="https://mrpingan.github.io/post/iptables-cha-kan-shu-ju-bao-chuan-shu-guo-cheng">
        </link>
        <updated>2020-03-22T02:11:02.000Z</updated>
        <content type="html"><![CDATA[<p>docker容器和宿主机在通过docker0网桥通信时，linux内核netfilter也参与其中，如果使用的iptables，可通过开启iptables的TRACE功能，查看数据包的传输过程。</p>
<pre><code class="language-linux"># 在宿主机上执行
iptables -t raw -A OUTPUT -p icmp -j TRACE
iptables -t raw -A PREROUTING -p icmp -j TRACE
</code></pre>
<p>通过上述设置，就可以在<code>/var/log/syslog</code>里看到数据包传输的过程了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ubuntu 安装es]]></title>
        <id>https://mrpingan.github.io/post/ubuntu-an-zhuang-es</id>
        <link href="https://mrpingan.github.io/post/ubuntu-an-zhuang-es">
        </link>
        <updated>2020-03-10T03:47:08.000Z</updated>
        <content type="html"><![CDATA[<p>使用dpkg安装es的时候，发现<code>/etc/elasticserach</code>目录下一直没有配置文件。重新安装也是这样。</p>
<pre><code># 可以尝试全部清除配置文件
dpkg -P package_name
</code></pre>
<p>然后重新安装，顺利完成</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[apollo笔记]]></title>
        <id>https://mrpingan.github.io/post/apollo-bi-ji</id>
        <link href="https://mrpingan.github.io/post/apollo-bi-ji">
        </link>
        <updated>2020-02-12T07:02:44.000Z</updated>
        <content type="html"><![CDATA[<p>apollo是携程开源的配置中心组件。可以将配置集中放置，并在配置变更后推送给应用，实现修改配置无需重启服务，而且配置有版本控制，可回滚。</p>
<h1 id="为什么要引入apollo">为什么要引入Apollo</h1>
<p>1、接入apollo可以让配置集中放置，配置热更新，服务无需重启。<br>
2、接入apollo更安全。配置如果放在服务源码中，如果服务源码泄露，配置也会随着泄露。<br>
参考文章：http://beckjin.com/2019/07/14/apollo-distributed/<br>
https://www.infoq.cn/article/ctrip-apollo-configuration-center-architecture</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[rabbitmq集群部分文档]]></title>
        <id>https://mrpingan.github.io/post/rabbitmq-ji-qun-bu-fen-wen-dang</id>
        <link href="https://mrpingan.github.io/post/rabbitmq-ji-qun-bu-fen-wen-dang">
        </link>
        <updated>2020-02-11T14:52:51.000Z</updated>
        <content type="html"><![CDATA[<p>一个RabbitMQ集群是一个或者多个rabbitmq单机节点逻辑上的组。每一个成员共享users,virtual hosts,queues,exchanges,bindings,runtime parameters和其他分布式的状态。</p>
<h1 id="集群发现">集群发现</h1>
<p>一个RabbitMQ可以通过多种方式构建</p>
<ul>
<li>在配置文件中指明节点</li>
<li>通过基于DNS解析为IP</li>
<li>使用AWS(EC2) instance discovery（需要通过插件）</li>
<li>通过基于consul discovery（需要通过插件）</li>
<li>通过etcd（需要通过插件）</li>
<li>通过<code>rabbitmqctl</code>手动指定</li>
</ul>
<h2 id="节点名">节点名</h2>
<p>RabbitMQ节点通过节点名来识别。一个rabbitmq节点包括两部分。一个前缀（通常是rabbit）和主机名。比如<code>rabbit@node1.messaging.svc.local</code><br>
集群中的节点名必须唯一。如果在一个服务器上运行了多了rabbitmq节点，则这些节点必须要使用不同的前缀，比如<code>rabbit1@hostname</code>和<code>rabbit2@hostname</code> 。<br>
在集群中，节点通过节点名来相互辨别和通信。这意味着每一个节点的hostname都可以正常解析。rabbitmq命令行工具也使用节点名来辨别节点。<br>
当一个节点启动时，将会检查是否这个节点已经注册，节点名也可以通过<code>RABBITMQ_NODENAME</code>环境变量设置。如果这个变量没有声明，将会使用<code>rabbit@hostname</code>的方式。<br>
如果系统使用了FQDNs，RabbitMQ节点和命令行工具必须要配置使用长节点名称。可以使用<code>RABBITMQ_USE_LONGNAME</code>环境变量为<code>true</code>,在命令行工具中，除了可以配置<code>RABBITMQ_USE_LONGNAME</code>环境变量或者<code>--longnames</code>参数。</p>
<h2 id="集群发现前提">集群发现前提</h2>
<h3 id="主机名可解析">主机名可解析</h3>
<p>可以在<code>/etc/hosts</code>中配置主机名来解析主机名。有一些场景，修改hosts文件是不被容许的。erlang虚拟机可以配置使用其他的方法来解析主机名，如配置DNS服务器，指定一个本地的文件，一个非标准hosts文件</p>
<h3 id="端口可达">端口可达</h3>
<p>RabbitMQ节点绑定到TCP端口来接受客户端和命令行工具的连接。一些进程和工具如<code>selinux</code>可能会阻止RabbitMQ绑定端口。当绑定端口失败时，RabbitMQ节点启动会失败。<br>
请保证节点之间的下列端口可访问：</p>
<ul>
<li>4369 a helper discovery daemon used by RabbitMQ nodes and CLI tools</li>
<li>5672,5671 AMQP 0-9-1 和1.0 客户端连接端口</li>
<li>25672 节点之间通信端口</li>
<li>15672 HTTP API客户端，管理后台启动端口</li>
<li>61613, 61614  STOMP clients without and with TLS (only if the STOMP plugin is enabled)</li>
<li>1883, 8883: (MQTT clients without and with TLS, if the MQTT plugin is enabled</li>
<li>15674: STOMP-over-WebSockets clients (only if the Web STOMP plugin is enabled)</li>
<li>15675: MQTT-over-WebSockets clients (only if the Web MQTT plugin is enabled)</li>
<li>15692: Prometheus metrics (only if the Prometheus plugin is enabled)</li>
</ul>
<h2 id="集群节点">集群节点</h2>
<p>一些分布式系统有leader和follower节点角色，在RabbitMQ中没有这些角色。所有的节点都是一样的，没有特别的节点。<br>
命令行工具或者HTTP API访问任何一个节点得到的数据都是一致的。<br>
RabbitMQ节点和命令行工具（如rabbitmqctl）使用一个cookie来决定是否他们可以相互通信。两个节点只有cookie一致才能正常通信。cookie是一段随机字母数字字符串，存储在本地文件。这个文件的权限也要控制，如设置为400或者600。<br>
如果这个文件不存在，Erlang虚拟机将会在rabbitmq启动的时候创建一个。<br>
cookie文件路径<br>
linux、MacOS、*BSD：/var/lib/rabbitmq/.erlang.cookie</p>
<h3 id="节点数量">节点数量</h3>
<p>集群中的数量最好为奇数个：1，3，5等等<br>
两个节点的集群极不推荐</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Django-rest-framework]]></title>
        <id>https://mrpingan.github.io/post/django-rest-framework</id>
        <link href="https://mrpingan.github.io/post/django-rest-framework">
        </link>
        <updated>2020-01-08T13:48:44.000Z</updated>
        <content type="html"><![CDATA[<p>1、浏览器api界面没有Login按钮</p>
<pre><code class="language-python">urlpatterns = [
    path('^api-auth/',include('rest_framework.urls',namespace=&quot;rest_framework_auth&quot;))
]
</code></pre>
<p>需要在<code>urls.py</code>中配置这一条路由，就可以看到登录按钮了<br>
<img src="https://mrpingan.github.io/post-images/1578491545380.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[好文一览]]></title>
        <id>https://mrpingan.github.io/post/hao-wen-yi-lan</id>
        <link href="https://mrpingan.github.io/post/hao-wen-yi-lan">
        </link>
        <updated>2019-12-27T14:15:42.000Z</updated>
        <content type="html"><![CDATA[<p>django源码解读：<br>
http://www.ziawang.com/article/302/#<br>
http://www.ziawang.com/blog/django/<br>
http://www.ziawang.com/article/169/</p>
<p>erp开源项目：<br>
https://sourcegraph.com/github.com/zhuinfo/Django-ERP/-/blob/plugin/wfusers.py</p>
<p>站点：<br>
http://devopstarter.info/page/9/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java项目ssl 证书验证错误]]></title>
        <id>https://mrpingan.github.io/post/java-xiang-mu-ssl-zheng-shu-yan-zheng-cuo-wu</id>
        <link href="https://mrpingan.github.io/post/java-xiang-mu-ssl-zheng-shu-yan-zheng-cuo-wu">
        </link>
        <updated>2019-11-20T12:38:49.000Z</updated>
        <content type="html"><![CDATA[<p>在java1.7的项目中启动java项目配置了ssl，报了如下错误</p>
<pre><code>sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
	at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:385)
	at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)
	at sun.security.validator.Validator.validate(Validator.java:260)
	at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:326)
	at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:231)
	at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:126)
	at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1428)
	at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:209)
	at sun.security.ssl.Handshaker.processLoop(Handshaker.java:913)
	at sun.security.ssl.Handshaker.process_record(Handshaker.java:849)
	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1023)
	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1332)
	at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:709)
	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:122)
	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:136)
	at SSLPoke.main(SSLPoke.java:31)
Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
	at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:196)
	at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:268)
	at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:380)
	... 15 more
</code></pre>
<p>虽然我申请的证书是权威机构认证的CA。这个错误指的是证书不被验证，可能有如下原因：</p>
<ul>
<li>证书是自签名证书，需要在keystore中导入自签名的CA</li>
<li>&lt;JAVA_HOME&gt;/jre/lib/security/cacerts文件太旧，没有包含最新的CA</li>
<li>证书错误</li>
</ul>
<p>针对前两种错误，需要把证书导入到keystore中</p>
<h2 id="导入证书到keystore中">导入证书到keystore中</h2>
<h3 id="命令行导出证书">命令行导出证书</h3>
<p>Unix(需要把google.com改成自己对应的域名):</p>
<pre><code>openssl s_client -connect google.com:443 -servername google.com:443 &lt; /dev/null | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' &gt; public.crt
</code></pre>
<p>windows：</p>
<pre><code>openssl s_client -connect google.com:443 -servername google.com:443 &lt; NUL | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' &gt; public.crt
</code></pre>
<h3 id="导入证书到keystore">导入证书到keystore</h3>
<pre><code>&lt;JAVA_HOME&gt;/bin/keytool -import -alias &lt;server_name&gt; -keystore &lt;JAVA_HOME&gt;/jre/lib/security/cacerts -file public.crt
</code></pre>
<p>参考文档：<br>
https://confluence.atlassian.com/kb/how-to-import-a-public-ssl-certificate-into-a-jvm-867025849.html#HowtoimportapublicSSLcertificateintoaJVM-commandline</p>
<p>https://confluence.atlassian.com/kb/unable-to-connect-to-ssl-services-due-to-pkix-path-building-failed-error-779355358.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ubuntu 安装问题]]></title>
        <id>https://mrpingan.github.io/post/ubuntu-an-zhuang-wen-ti</id>
        <link href="https://mrpingan.github.io/post/ubuntu-an-zhuang-wen-ti">
        </link>
        <updated>2019-11-11T11:55:22.000Z</updated>
        <content type="html"><![CDATA[<p>问题片段</p>
<pre><code>sh: 0: getcwd() failed: No such file or directory
sh: 0: getcwd() failed: No such file or directory
sh: 0: getcwd() failed: No such file or directory
sh: 0: getcwd() failed: No such file or directory
sh: 0: getcwd() failed: No such file or directory
sh: 0: getcwd() failed: No such file or directory
sh: 0: getcwd() failed: No such file or directory
</code></pre>
<p>解决：</p>
<ul>
<li>到root目录下区执行命令</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[openldap 配置mirrormode]]></title>
        <id>https://mrpingan.github.io/post/openldap-pei-zhi-mirrormode</id>
        <link href="https://mrpingan.github.io/post/openldap-pei-zhi-mirrormode">
        </link>
        <updated>2019-11-08T03:28:40.000Z</updated>
        <content type="html"><![CDATA[<h1 id="简介">简介</h1>
<p>MirrorMode 模式镜像同步模式，而且主服务器互相以推的方式实现目录树条目同步，最多允许且两台机器为主服务器。如果要添加更多节点，此时只能添加多台从服务器，而不能将添加的节点配置为主服务器</p>
<h1 id="准备">准备</h1>
<table>
<thead>
<tr>
<th>用途</th>
<th>IP</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>provider1</td>
<td>192.168.33.10</td>
<td></td>
</tr>
<tr>
<td>provider2</td>
<td>192.168.33.11</td>
<td></td>
</tr>
</tbody>
</table>
<p>两台服务器互为主备，但是只能在一个provider上写。</p>
<h1 id="安装ldap">安装ldap</h1>
<pre><code>apt install slapd ldap-utils

#重新配置
dpkg-reconfigure slapd
</code></pre>
<p>dn: dc=ping,dc=cn<br>
管理员密码：admin</p>
<p>两台服务器的DIT要保持一致</p>
<h1 id="开启日志如果已开启可忽略">开启日志(如果已开启可忽略)</h1>
<p>log.ldif文件内容如下：</p>
<pre><code>dn: cn=config
changetype: modify
replace: olcLogLevel
olcLogLevel: stats sync
</code></pre>
<p>应用配置：</p>
<pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f log.ldif
</code></pre>
<h1 id="加载syncprov模块">加载syncprov模块</h1>
<p>sync.ldif文件如下：</p>
<pre><code>dn: cn=module{0},cn=config
changetype: modify
add: olcModuleLoad
olcModuleLoad: syncprov.la

dn: olcOverlay=syncprov,olcDatabase={1}hdb,cn=config
changetype: add
objectClass: olcOverlayConfig
objectClass: olcSyncProvConfig
olcOverlay: syncprov
olcSpCheckpoint: 100 10
olcSpSessionLog: 100
</code></pre>
<p>注意：</p>
<ul>
<li>指定的dn存在</li>
<li>指定的Database要存在</li>
<li>模块文件存在，ubuntu 的模块目录一般在<code>/usr/lib/ldap</code>目录下,如果在其他目录下，可通过<code>olcModulePath</code>指定目录，也可查看<code>cn=module{0}.ldif</code>文件<code>olcModulePath</code>是否被指定</li>
</ul>
<p>应用配置：</p>
<pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f sync.ldif
</code></pre>
<h1 id="配置mirror模式">配置mirror模式</h1>
<p>master01.ldif文件内容如下：<br>
master01的ip地址为: <code>192.168.33.10</code></p>
<pre><code>dn: cn=config
changetype: modify
replace: olcServerID
olcServerID: 1

dn: olcDatabase={1}hdb,cn=config
changetype: modify
replace: olcSyncRepl
olcSyncRepl: rid=001
             provider=ldap://192.168.33.11:389
             bindmethod=simple
             binddn=&quot;cn=admin,dc=ping,dc=cn&quot;
             credentials=admin
             searchbase=&quot;dc=ping,dc=cn&quot;
             filter=&quot;(objectClass=*)&quot;
             scope=sub
             schemachecking=off
             attrs=&quot;*,+&quot;
             type=refreshAndPersist
             retry=&quot;5 5 300 +&quot;
             interval=00:00:01:00
-
add: olcMirrorMode
olcMirrorMode: TRUE
-
add: olcDbIndex
olcDbIndex: entryUUID eq
-
add: olcDbIndex
olcDbIndex: entryCSN eq
</code></pre>
<p>注意：</p>
<ul>
<li>此处的<code>provider</code>指定的另一台服务器的ip</li>
<li><code>rid</code>要保持一致</li>
<li><code>olcServerID</code>要区分</li>
</ul>
<p>应用配置：</p>
<pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f master01.ldif
</code></pre>
<p>master02.ldif文件内容如下：</p>
<pre><code>dn: cn=config
changetype: modify
replace: olcServerID
olcServerID: 2

dn: olcDatabase={1}hdb,cn=config
changetype: modify
replace: olcSyncRepl
olcSyncRepl: rid=001
             provider=ldap://192.168.33.10:389
             bindmethod=simple
             binddn=&quot;cn=admin,dc=ping,dc=cn&quot;
             credentials=admin
             searchbase=&quot;dc=ping,dc=cn&quot;
             filter=&quot;(objectClass=*)&quot;
             scope=sub
             schemachecking=off
             attrs=&quot;*,+&quot;
             type=refreshAndPersist
             retry=&quot;5 5 300 +&quot;
             interval=00:00:01:00
-
add: olcMirrorMode
olcMirrorMode: TRUE
-
add: olcDbIndex
olcDbIndex: entryUUID eq
-
add: olcDbIndex
olcDbIndex: entryCSN eq
</code></pre>
<p>应用配置:</p>
<pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f master02.ldif
</code></pre>
<h1 id="验证">验证</h1>
<p>1、查看日志：<br>
<img src="https://mrpingan.github.io/post-images/1573189656518.png" alt=""><br>
并未看到任何错误</p>
<p>2、添加用户<br>
在master01上添加用户，看master02上是否被同步</p>
<p>验证通过！</p>
]]></content>
    </entry>
</feed>